{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, Concatenate, Conv1D, Lambda, Add, Activation\n",
    "from tensorflow.keras.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.base_blocks = self.init_base_block()\n",
    "        self.concat = tf.concat\n",
    "        self.copy = tf.identity\n",
    "        self.num_units = [1, 4, 7, 22, 56, 43]\n",
    "        self.inter_blocks = [self.init_kth_inter_block(k, self.num_units[k]) for k in range(6)]\n",
    "        self.out_blocks = [self.init_kth_out_block(k, self.num_units[k]) for k in range(6)]\n",
    "        self.postproc_layers = [self.init_kth_post_proc_layer(k) for k in range(6)]\n",
    "\n",
    "    def init_kth_inter_block(self, k: int, out_units):\n",
    "        filter_by_size = lambda x: x[ (x > out_units * 8) & (x <= out_units * 32)][::-1]\n",
    "        num_units = filter_by_size(2 ** np.arange(11))\n",
    "        # modify here\n",
    "        block = tf.keras.Sequential()\n",
    "        block.add(Dense(num_units[0], name='l'+str(k)+'_inter_dense_0', input_shape=(512,), use_bias=False, kernel_initializer=ln_init))\n",
    "        block.add(BatchNormalization())\n",
    "        block.add(Activation('relu'))\n",
    "        block.add(Dense(num_units[1], name='l'+str(k)+'_inter_dense_1', use_bias=False, kernel_initializer=ln_init))\n",
    "        block.add(BatchNormalization())\n",
    "        block.add(Activation('relu'))\n",
    "        return block\n",
    "\n",
    "    def init_kth_out_block(self, k: int, out_units):\n",
    "        n_units = 2 ** np.arange(0, 11)[::-1]\n",
    "        n_units = n_units[(n_units > (4 * out_units)).sum() + 1]\n",
    "        # modify here\n",
    "        block = tf.keras.Sequential()\n",
    "        block.add(Dense(n_units, name='l'+str(k)+'_out_dense_0', use_bias=False, kernel_initializer=ln_init,\n",
    "                kernel_regularizer='l2'))\n",
    "        block.add(BatchNormalization())\n",
    "        block.add(Activation('relu'))\n",
    "        block.add(Dense(n_units, name='l'+str(k)+'_out_dense_1', use_bias=False, kernel_initializer=ln_init,\n",
    "                kernel_regularizer='l2'))\n",
    "        block.add(BatchNormalization())\n",
    "        block.add(Activation('relu'))\n",
    "        block.add(Dense(n_units, name='l'+str(k)+'_out_dense_1', use_bias=False, kernel_initializer=ln_init,\n",
    "                kernel_regularizer='l2'))\n",
    "        block.add(BatchNormalization())\n",
    "        block.add(Activation('relu'))\n",
    "        block.add(Dense(out_units, name='l'+str(k), activation='sigmoid', use_bias=False))\n",
    "        return block\n",
    "\n",
    "    def init_base_block(self):\n",
    "        block = tf.keras.Sequential()\n",
    "        block.add(Conv1D(64, kernel_size=2, strides=1, padding='same', activation='relu', \n",
    "                          kernel_initializer=ln_init, use_bias=False, input_shape=(1462, 7)))\n",
    "        block.add(Conv1D(64, kernel_size=2, strides=2, activation='relu', kernel_initializer=ln_init, use_bias=False))\n",
    "        block.add(Conv1D(128, kernel_size=3, strides=2, activation='relu', kernel_initializer=ln_init, use_bias=False))\n",
    "        block.add(Conv1D(128, kernel_size=3, strides=2, activation='relu', kernel_initializer=ln_init, use_bias=False))\n",
    "        block.add(Conv1D(256, kernel_size=2, strides=2, activation='relu', kernel_initializer=ln_init, use_bias=False))\n",
    "        block.add(Conv1D(256, kernel_size=4, strides=3, activation='relu', kernel_initializer=ln_init, use_bias=False))\n",
    "        block.add(Conv1D(512, kernel_size=2, strides=2, activation='relu', kernel_initializer=ln_init, use_bias=False))\n",
    "        block.add(Conv1D(512, kernel_size=3, strides=2, activation='relu', kernel_initializer=ln_init, use_bias=False,\n",
    "                          kernel_regularizer='l2'))\n",
    "        block.add(Conv1D(512, kernel_size=7, strides=1, use_bias=False, kernel_initializer=ln_init, kernel_regularizer='l2'))\n",
    "        block.add(BatchNormalization())\n",
    "        block.add(Activation('relu'))\n",
    "        block.add(Flatten())\n",
    "        return block\n",
    "\n",
    "    def init_kth_post_proc_layer(self, k):\n",
    "        def scale_output(x):\n",
    "            total_contrib = tf.constant([[1]], dtype=tf.float32, shape=(1, 1))\n",
    "            unknown_contrib = tf.subtract(total_contrib, tf.keras.backend.sum(x, keepdims=True, axis=1))\n",
    "            contrib = tf.keras.backend.relu(tf.keras.backend.concatenate( (x, unknown_contrib), axis=1))\n",
    "            scaled_contrib = tf.divide(contrib, tf.keras.backend.sum(contrib, keepdims=True, axis=1))\n",
    "            return scaled_contrib\n",
    "        return Lambda(scale_output, name='l'+str(k)+'_y')\n",
    "\n",
    "    def call(self, input, training=False):\n",
    "        base = self.base_blocks(input, training=training)\n",
    "        inter_factors = [self.inter_blocks[i](base, training=training) for i in range(6)]\n",
    "        concat_factors = [self.concat(inter_factors[0:i], axis=1) for i in range(1, 7)]\n",
    "        y_s = [self.out_blocks[i](concat_factors[i], training=training) for i in range(6)]\n",
    "        (l0_y, l1_y, l2_y, l3_y, l4_y, l5_y) = (self.postproc_layers[i](y_s[i], training=training) for i in range(6))\n",
    "        return l0_y, l1_y, l2_y, l3_y, l4_y, l5_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_150 (Sequential)  (None, 512)               3296128   \n",
      "_________________________________________________________________\n",
      "sequential_151 (Sequential)  (None, 16)                17088     \n",
      "_________________________________________________________________\n",
      "sequential_152 (Sequential)  (None, 64)                74496     \n",
      "_________________________________________________________________\n",
      "sequential_153 (Sequential)  (None, 64)                74496     \n",
      "_________________________________________________________________\n",
      "sequential_154 (Sequential)  (None, 256)               396288    \n",
      "_________________________________________________________________\n",
      "sequential_155 (Sequential)  (None, 512)               1054720   \n",
      "_________________________________________________________________\n",
      "sequential_156 (Sequential)  (None, 512)               1054720   \n",
      "_________________________________________________________________\n",
      "sequential_157 (Sequential)  multiple                  66        \n",
      "_________________________________________________________________\n",
      "sequential_158 (Sequential)  multiple                  896       \n",
      "_________________________________________________________________\n",
      "sequential_159 (Sequential)  multiple                  1432      \n",
      "_________________________________________________________________\n",
      "sequential_160 (Sequential)  multiple                  15936     \n",
      "_________________________________________________________________\n",
      "sequential_161 (Sequential)  multiple                  70912     \n",
      "_________________________________________________________________\n",
      "sequential_162 (Sequential)  multiple                  102848    \n",
      "_________________________________________________________________\n",
      "l0_y (Lambda)                multiple                  0         \n",
      "_________________________________________________________________\n",
      "l1_y (Lambda)                multiple                  0         \n",
      "_________________________________________________________________\n",
      "l2_y (Lambda)                multiple                  0         \n",
      "_________________________________________________________________\n",
      "l3_y (Lambda)                multiple                  0         \n",
      "_________________________________________________________________\n",
      "l4_y (Lambda)                multiple                  0         \n",
      "_________________________________________________________________\n",
      "l5_y (Lambda)                multiple                  0         \n",
      "=================================================================\n",
      "Total params: 6,160,026\n",
      "Trainable params: 6,149,390\n",
      "Non-trainable params: 10,636\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ln_init = tf.keras.initializers.GlorotUniform()\n",
    "model = Model()\n",
    "model.build(input_shape=(None, 1462, 7))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model, to_file='model.png', show_shapes=True, show_layer_names=True,\n",
    "    rankdir='TB', expand_nested=True, dpi=96\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
